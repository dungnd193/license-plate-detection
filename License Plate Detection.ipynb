{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c682be74",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "%matplotlib inline "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0a1d8056",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /Users/dungnd/.cache/torch/hub/ultralytics_yolov5_master\n",
      "YOLOv5 ðŸš€ 2023-6-25 Python-3.10.9 torch-2.0.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "YOLOv5s summary: 213 layers, 7225885 parameters, 0 gradients\n",
      "Adding AutoShape... \n"
     ]
    }
   ],
   "source": [
    "model = torch.hub.load('ultralytics/yolov5', 'yolov5s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "51c62e11",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://github.com/ultralytics/yolov5/zipball/master\" to /Users/dungnd/.cache/torch/hub/master.zip\n",
      "YOLOv5 ðŸš€ 2023-6-25 Python-3.10.9 torch-2.0.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 157 layers, 7012822 parameters, 0 gradients, 15.8 GFLOPs\n",
      "Adding AutoShape... \n"
     ]
    }
   ],
   "source": [
    "model = torch.hub.load('ultralytics/yolov5', 'custom', path='yolov5/runs/train/exp2/weights/best.pt', force_reload=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c98b5b67",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pre_processing_img(crop_img):\n",
    "    # grayscale region within bounding box\n",
    "    gray = cv2.cvtColor(crop_img, cv2.COLOR_RGB2GRAY)\n",
    "\n",
    "    # resize image to three times as large as original for better readability\n",
    "    gray = cv2.resize(gray, None, fx = 3, fy = 3, interpolation = cv2.INTER_CUBIC)\n",
    "\n",
    "    # perform gaussian blur to smoothen image\n",
    "    blur = cv2.GaussianBlur(gray, (5,5), 0)\n",
    "\n",
    "    # threshold the image using Otsus method to preprocess for tesseract\n",
    "    ret, binary = cv2.threshold(blur, 127, 255,cv2.THRESH_BINARY | cv2.THRESH_OTSU)\n",
    "\n",
    "    # perform another blur on character region\n",
    "    result = cv2.medianBlur(binary, 5)\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "353de10b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_text(region, ocr_result, region_threshold=0.2):\n",
    "    rectangle_size = region.shape[0]*region.shape[1]\n",
    "    plate = []\n",
    "    for result in ocr_result:\n",
    "        length = np.sum(np.subtract(result[0][1], result[0][0]))\n",
    "        height = np.sum(np.subtract(result[0][2], result[0][1]))\n",
    "        if length*height / rectangle_size > region_threshold:\n",
    "            plate.append(result)\n",
    "    return plate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "0cec145c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# img_path = os.path.join('data', 'images', 'CarLongPlate137.jpg')\n",
    "img_path = os.path.join('/Users/dungnd/Desktop/Workspace/AI/license-plate-detection/server/test_img', 'test_17.jpeg')\n",
    "# img_path = 'https://www.roadpol.eu/images/2022/SEP/Russian.jpg'\n",
    "# img_path = 'https://image.vietnamnews.vn/uploadvnnews/Article/2017/6/15/5b3929415d1_wize16423115PM.jpg'\n",
    "# img_path = 'https://media.urbanistnetwork.com/saigoneer/article-images/legacy/lB85cVQb.jpg'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "dd5c7a68",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 4032x3024 2 plates\n",
      "Speed: 3.7ms pre-process, 147.1ms inference, 0.6ms NMS per image at shape (1, 3, 640, 480)\n"
     ]
    }
   ],
   "source": [
    "img = cv2.imread(img_path, cv2.IMREAD_COLOR)\n",
    "img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "results = model(img)\n",
    "results.print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "c0cedacc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>xcenter</th>\n",
       "      <th>ycenter</th>\n",
       "      <th>width</th>\n",
       "      <th>height</th>\n",
       "      <th>confidence</th>\n",
       "      <th>class</th>\n",
       "      <th>name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2194.066162</td>\n",
       "      <td>2805.538086</td>\n",
       "      <td>521.602539</td>\n",
       "      <td>399.501465</td>\n",
       "      <td>0.94805</td>\n",
       "      <td>0</td>\n",
       "      <td>plate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>724.309570</td>\n",
       "      <td>1587.698242</td>\n",
       "      <td>271.268005</td>\n",
       "      <td>244.688477</td>\n",
       "      <td>0.87094</td>\n",
       "      <td>0</td>\n",
       "      <td>plate</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       xcenter      ycenter       width      height  confidence  class   name\n",
       "0  2194.066162  2805.538086  521.602539  399.501465     0.94805      0  plate\n",
       "1   724.309570  1587.698242  271.268005  244.688477     0.87094      0  plate"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results.pandas().xywh[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "cda6d290",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Save cropped image - crop_images/plate_1.jpeg\n",
      "Save cropped image - crop_images/plate_2.jpeg\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save cropped image\n",
    "def delete_all_cropped():\n",
    "    folder_path = '/Users/dungnd/Desktop/Workspace/AI/license-plate-detection/server/crop_images'\n",
    "\n",
    "    for file_name in os.listdir(folder_path):\n",
    "        file_path = os.path.join(folder_path, file_name)\n",
    "        if os.path.isfile(file_path):\n",
    "            os.remove(file_path)\n",
    "delete_all_cropped()\n",
    "lp_list = results.pandas().xywh[0].values.tolist()\n",
    "for idx, lp in enumerate(lp_list):\n",
    "    x,y,w,h =  lp[0], lp[1], lp[2], lp[3]\n",
    "    x1 = int(x - w / 2)\n",
    "    y1 = int(y - h / 2)\n",
    "    x2 = int(x + w / 2)\n",
    "    y2 = int(y + h / 2)\n",
    "    crop_img = img[int(y-h//2-5):int(y+h//2+5) , int(x-w//2-5):int(x+w//2+5)]\n",
    "    crop_img = cv2.cvtColor(crop_img, cv2.COLOR_BGR2RGB)\n",
    "#     result = pre_processing_img(crop_img)\n",
    "    result = crop_img\n",
    "    cv2.imwrite(\"/Users/dungnd/Desktop/Workspace/AI/license-plate-detection/server/crop_images/plate_\" + str(idx+1) + \".jpeg\", result)\n",
    "    cv2.rectangle(img, (x1, y1), (x2, y2), (0, 255, 0), 5)\n",
    "    print(\"Save cropped image - crop_images/plate_\" + str(idx+1) + \".jpeg\")\n",
    "cv2.imwrite(\"/Users/dungnd/Desktop/Workspace/AI/license-plate-detection/server/image_bounding_box/bd.jpeg\", cv2.cvtColor(img, cv2.COLOR_BGR2RGB))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "39e1a596",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.imshow(np.squeeze(results.render()))\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "32edf9df",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Neither CUDA nor MPS are available - defaulting to CPU. Note: This module is much faster with a GPU.\n"
     ]
    }
   ],
   "source": [
    "import easyocr\n",
    "EASY_OCR = easyocr.Reader(['en']) ### initiating easyocr\n",
    "region_threshold = 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c88a21f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "ocr_result = EASY_OCR.readtext(img)\n",
    "print(filter_text(img, ocr_result))\n",
    "# for result in ocr_result:\n",
    "  # print(result)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
