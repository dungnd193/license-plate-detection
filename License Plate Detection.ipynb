{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c682be74",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "from core.utils import *\n",
    "%matplotlib inline "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0a1d8056",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /Users/dungnd/.cache/torch/hub/ultralytics_yolov5_master\n",
      "YOLOv5 ðŸš€ 2023-6-18 Python-3.10.9 torch-2.0.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "YOLOv5s summary: 213 layers, 7225885 parameters, 0 gradients\n",
      "Adding AutoShape... \n"
     ]
    }
   ],
   "source": [
    "model = torch.hub.load('ultralytics/yolov5', 'yolov5s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "51c62e11",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://github.com/ultralytics/yolov5/zipball/master\" to /Users/dungnd/.cache/torch/hub/master.zip\n",
      "YOLOv5 ðŸš€ 2023-6-18 Python-3.10.9 torch-2.0.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 157 layers, 7012822 parameters, 0 gradients, 15.8 GFLOPs\n",
      "Adding AutoShape... \n"
     ]
    }
   ],
   "source": [
    "model = torch.hub.load('ultralytics/yolov5', 'custom', path='yolov5/runs/train/exp2/weights/best.pt', force_reload=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c98b5b67",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pre_processing_img(crop_img):\n",
    "    # grayscale region within bounding box\n",
    "    gray = cv2.cvtColor(crop_img, cv2.COLOR_RGB2GRAY)\n",
    "\n",
    "    # resize image to three times as large as original for better readability\n",
    "    gray = cv2.resize(gray, None, fx = 3, fy = 3, interpolation = cv2.INTER_CUBIC)\n",
    "\n",
    "    # perform gaussian blur to smoothen image\n",
    "    blur = cv2.GaussianBlur(gray, (5,5), 0)\n",
    "\n",
    "    # threshold the image using Otsus method to preprocess for tesseract\n",
    "    ret, thresh = cv2.threshold(gray, 0, 255, cv2.THRESH_OTSU | cv2.THRESH_BINARY_INV)\n",
    "\n",
    "    # create rectangular kernel for dilation\n",
    "    rect_kern = cv2.getStructuringElement(cv2.MORPH_RECT, (5,5))\n",
    "    # apply dilation to make regions more clear\n",
    "    dilation = cv2.dilate(thresh, rect_kern, iterations = 1)\n",
    "\n",
    "    # Invert the black and white background image\n",
    "    inv_thresh = cv2.bitwise_not(thresh)\n",
    "    inv_thresh = cv2.bitwise_not(inv_thresh)\n",
    "\n",
    "    # Perform bitwise AND operation between the grayscale image and inverted background\n",
    "    result = cv2.bitwise_and(dilation, dilation, mask=inv_thresh)\n",
    "    # perform another blur on character region\n",
    "    result = cv2.medianBlur(result, 5)\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0cec145c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# img_path = os.path.join('data', 'images', 'CarLongPlate137.jpg')\n",
    "img_path = os.path.join('test_img', 'test_9.jpeg')\n",
    "# img_path = 'https://www.roadpol.eu/images/2022/SEP/Russian.jpg'\n",
    "# img_path = 'https://image.vietnamnews.vn/uploadvnnews/Article/2017/6/15/5b3929415d1_wize16423115PM.jpg'\n",
    "# img_path = 'https://media.urbanistnetwork.com/saigoneer/article-images/legacy/lB85cVQb.jpg'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dd5c7a68",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 4032x3024 1 plate\n",
      "Speed: 18.2ms pre-process, 206.8ms inference, 20.4ms NMS per image at shape (1, 3, 640, 480)\n"
     ]
    }
   ],
   "source": [
    "img = cv2.imread(img_path, cv2.IMREAD_COLOR)\n",
    "img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "results = model(img)\n",
    "results.print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c0cedacc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>xcenter</th>\n",
       "      <th>ycenter</th>\n",
       "      <th>width</th>\n",
       "      <th>height</th>\n",
       "      <th>confidence</th>\n",
       "      <th>class</th>\n",
       "      <th>name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1483.689575</td>\n",
       "      <td>2212.386475</td>\n",
       "      <td>886.713379</td>\n",
       "      <td>688.322144</td>\n",
       "      <td>0.964241</td>\n",
       "      <td>0</td>\n",
       "      <td>plate</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       xcenter      ycenter       width      height  confidence  class   name\n",
       "0  1483.689575  2212.386475  886.713379  688.322144    0.964241      0  plate"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results.pandas().xywh[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cda6d290",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Save cropped image - crop_images/plate_1.jpeg\n"
     ]
    }
   ],
   "source": [
    "# Save cropped image\n",
    "delete_all_cropped()\n",
    "lp_list = results.pandas().xywh[0].values.tolist()\n",
    "for idx, lp in enumerate(lp_list):\n",
    "    x,y,w,h =  lp[0], lp[1], lp[2], lp[3]\n",
    "    crop_img = img[int(y-h//2-5):int(y+h//2+5) , int(x-w//2-5):int(x+w//2+5)]\n",
    "    crop_img = cv2.cvtColor(crop_img, cv2.COLOR_BGR2RGB)\n",
    "#     result = pre_processing_img(crop_img)\n",
    "    result = crop_img\n",
    "    cv2.imwrite(\"crop_images/plate_\" + str(idx+1) + \".jpeg\", result)\n",
    "    print(\"Save cropped image - crop_images/plate_\" + str(idx+1) + \".jpeg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "39e1a596",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(np.squeeze(results.render()))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61c56937",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
