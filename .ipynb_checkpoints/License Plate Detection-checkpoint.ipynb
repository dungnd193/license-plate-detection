{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c682be74",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "%matplotlib inline "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0a1d8056",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /Users/dungnd/.cache/torch/hub/ultralytics_yolov5_master\n",
      "YOLOv5 ðŸš€ 2023-6-18 Python-3.10.9 torch-2.0.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "YOLOv5s summary: 213 layers, 7225885 parameters, 0 gradients\n",
      "Adding AutoShape... \n"
     ]
    }
   ],
   "source": [
    "model = torch.hub.load('ultralytics/yolov5', 'yolov5s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "51c62e11",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://github.com/ultralytics/yolov5/zipball/master\" to /Users/dungnd/.cache/torch/hub/master.zip\n",
      "YOLOv5 ðŸš€ 2023-6-19 Python-3.10.9 torch-2.0.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 157 layers, 7012822 parameters, 0 gradients, 15.8 GFLOPs\n",
      "Adding AutoShape... \n"
     ]
    }
   ],
   "source": [
    "model = torch.hub.load('ultralytics/yolov5', 'custom', path='yolov5/runs/train/exp2/weights/best.pt', force_reload=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c98b5b67",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pre_processing_img(crop_img):\n",
    "    # grayscale region within bounding box\n",
    "    gray = cv2.cvtColor(crop_img, cv2.COLOR_RGB2GRAY)\n",
    "\n",
    "    # resize image to three times as large as original for better readability\n",
    "    gray = cv2.resize(gray, None, fx = 3, fy = 3, interpolation = cv2.INTER_CUBIC)\n",
    "\n",
    "    # perform gaussian blur to smoothen image\n",
    "    blur = cv2.GaussianBlur(gray, (5,5), 0)\n",
    "\n",
    "    # threshold the image using Otsus method to preprocess for tesseract\n",
    "    ret, binary = cv2.threshold(blur, 127, 255,cv2.THRESH_BINARY | cv2.THRESH_OTSU)\n",
    "\n",
    "    # perform another blur on character region\n",
    "    result = cv2.medianBlur(binary, 5)\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "0cec145c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# img_path = os.path.join('data', 'images', 'CarLongPlate137.jpg')\n",
    "img_path = os.path.join('/Users/dungnd/Desktop/Workspace/AI/license-plate-detection/server/test_img', 'test_14.jpeg')\n",
    "# img_path = 'https://www.roadpol.eu/images/2022/SEP/Russian.jpg'\n",
    "# img_path = 'https://image.vietnamnews.vn/uploadvnnews/Article/2017/6/15/5b3929415d1_wize16423115PM.jpg'\n",
    "# img_path = 'https://media.urbanistnetwork.com/saigoneer/article-images/legacy/lB85cVQb.jpg'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "dd5c7a68",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 2048x946 2 plates\n",
      "Speed: 6.4ms pre-process, 137.7ms inference, 1.9ms NMS per image at shape (1, 3, 640, 320)\n"
     ]
    }
   ],
   "source": [
    "img = cv2.imread(img_path, cv2.IMREAD_COLOR)\n",
    "img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "results = model(img)\n",
    "results.print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c0cedacc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>xcenter</th>\n",
       "      <th>ycenter</th>\n",
       "      <th>width</th>\n",
       "      <th>height</th>\n",
       "      <th>confidence</th>\n",
       "      <th>class</th>\n",
       "      <th>name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>573.694092</td>\n",
       "      <td>1151.544434</td>\n",
       "      <td>350.110077</td>\n",
       "      <td>108.999268</td>\n",
       "      <td>0.883538</td>\n",
       "      <td>0</td>\n",
       "      <td>plate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>693.755066</td>\n",
       "      <td>1882.517334</td>\n",
       "      <td>55.867798</td>\n",
       "      <td>38.561646</td>\n",
       "      <td>0.286849</td>\n",
       "      <td>0</td>\n",
       "      <td>plate</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      xcenter      ycenter       width      height  confidence  class   name\n",
       "0  573.694092  1151.544434  350.110077  108.999268    0.883538      0  plate\n",
       "1  693.755066  1882.517334   55.867798   38.561646    0.286849      0  plate"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results.pandas().xywh[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "cda6d290",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Save cropped image - crop_images/plate_1.jpeg\n"
     ]
    }
   ],
   "source": [
    "# Save cropped image\n",
    "def delete_all_cropped():\n",
    "    folder_path = '/Users/dungnd/Desktop/Workspace/AI/license-plate-detection/server/crop_images'\n",
    "\n",
    "    for file_name in os.listdir(folder_path):\n",
    "        file_path = os.path.join(folder_path, file_name)\n",
    "        if os.path.isfile(file_path):\n",
    "            os.remove(file_path)\n",
    "delete_all_cropped()\n",
    "lp_list = results.pandas().xywh[0].values.tolist()\n",
    "for idx, lp in enumerate(lp_list):\n",
    "    x,y,w,h =  lp[0], lp[1], lp[2], lp[3]\n",
    "    crop_img = img[int(y-h//2-5):int(y+h//2+5) , int(x-w//2-5):int(x+w//2+5)]\n",
    "    crop_img = cv2.cvtColor(crop_img, cv2.COLOR_BGR2RGB)\n",
    "#     result = pre_processing_img(crop_img)\n",
    "    result = crop_img\n",
    "    cv2.imwrite(\"/Users/dungnd/Desktop/Workspace/AI/license-plate-detection/server/crop_images/plate_\" + str(idx+1) + \".jpeg\", result)\n",
    "    print(\"Save cropped image - crop_images/plate_\" + str(idx+1) + \".jpeg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "39e1a596",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(np.squeeze(results.render()))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ac8e4e29",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Neither CUDA nor MPS are available - defaulting to CPU. Note: This module is much faster with a GPU.\n",
      "Downloading detection model, please wait. This may take several minutes depending upon your network connection.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100.0% Complete"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading recognition model, please wait. This may take several minutes depending upon your network connection.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100.0% Complete"
     ]
    }
   ],
   "source": [
    "import easyocr\n",
    "EASY_OCR = easyocr.Reader(['en']) ### initiating easyocr\n",
    "region_threshold = 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1945e612",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread(\"plate_1.jpeg\")\n",
    "plt.imshow(img)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "847b2fba",
   "metadata": {},
   "outputs": [],
   "source": [
    "ocr_result = EASY_OCR.readtext(img)\n",
    "print(filter_text(img, ocr_result))\n",
    "# for result in ocr_result:\n",
    "  # print(result)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
